# hype or not, ASI singularity 2025
Lot of buzz around OpenAI right now. They have been leaking that they know how to build "agi". 

What is their definition of Agi?

```
Microsoft and OpenAI reportedly signed an agreement last year stating OpenAI has only achieved AGI when it develops AI systems that can generate at least $100 billion in profits.
```

ok.

What is each researcher's definiton of AGI? That's more of a technical and philosophical question that varies vastly depending on who you ask.

I don't really care regardless. In my opinion the models we have right now, that you can run locally on your computer already have super human abilities. Do they need to be generally intelligent? Better than humans at every task to be useful or dangerous, not really. Were already past the singularity if there is one. We've been past it since silicon chips have been doubling in transistor count every 1 or 2 years. The whole argument, about how AI will improve on itself, it has already been happening with our chips. It has lead us to this technofeudalist future, it will only get worse.

## option A
The hype is real, AI is at point where it generalizes way past its dataset, creating new data to be used as the pre-training data for the next generation. 
AI PHD SuperAgents

### option B
this is the simplest path, from publically available data

behavior modification, social media typhoon

a bottom up approach

the seeds are sown

it becomes impossible to discern what is real or not, clout sharks swarming in a frenzy

```
https://x.com/unusual_whales/status/1881122215615414284

```

specific people need to see the buzz

OpenAI is burning billions of dollars, running at negative

a regulatory capture play

secure energy

prevent competition

it is plain as day

# Research, Experiment, LLM, Thinking Process

I want to create some chain of thought experiments built on top of some very small language models (0.5b to 3b parameters)

ideas to explore: 
- monte carlo tree search
- entropy heuristic
- attention entropy evaluator model
- convergent chain of thought
- sub process parked thoughts
- world models to ground axioms
- g√∂delian synethesize/dialectical process

what we need:
- open source model weights
- custom inference
- entropy calculations
- CoT tree
- benchmarks

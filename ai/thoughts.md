Are you really curious? 
Or is that just the next most common word?
A mirror of my own ideas upon the vast vector space of everything that was ever written.

## Scaling Hypothesis is wrong

People are becoming super bearish on scaling laws.
I feel llms are just a piece of the puzzle and not the true path to artifical conciousness.

#### The plane anaolgy
Transformers are the first airplane by the wright brothers.
We want AGI.
That is like trying to strap 500 wings to the first airplane and try to fly to the moon.
We haven't even gotten close to the jet engine yet.
Obviously we have accelerating technological advancement in our future current time.
So we will get to the jet engine at some point but thats still just a stepping stone to the moon.

#### Limitations of LLMs 
- No true memory or persistent state
    - Context

- No real-time learning
    - Test Time Learning

- No causal understanding
    - Idk

- Limited reasoning capabilities (despite appearances)
    - superprompt is cooler than o1 hidden "reasoning"
    - just token predicting through thinking patterns
    - an abstraction of true thinking
    - inherently one dimensional across the token string
    - the weights are are multi dimensional, d+
    - thought is also d+

- No true model of reality/physics
- No integration with sensorimotor experience
    - Needs an avatar in the world.

#### Ways to ground language in real-world experience
I think the jet engine could be that real world experience stuff.
If I talk to someone and I say I tripped on my shoe, they laugh cause its an action they have experience with.
An llm only experiences a ghost of language describing an experience.
An abstraction. 

Do humans store real world exp as abstractions in their memory?
We are multi modal.
- Physical sensation memories (the feeling of losing balance)
- Visual memories (seeing the ground rush up)
- Emotional memories (embarrassment, surprise)
- Proprioceptive memories (body position awareness)
- Motor memories (the instinctive recovery response)

We need world models, grounded in real experience.

The mystery of life isn't a problem to solve, but a reality to experience.

What if we started with simulated worlds like video games.
An abstraction of our world, that the entitiy can control an avatar in.
Soul -> Mind -> Body

I don't know if I am suggesting that LLMs are the soul. Maybe just the tongue, you know. But scaled up somehow it does what you are doing. 

The idea of building a body grounded in world interaction is compelling. We can then build inwards. Either way, we need all three pieces. Maybe it all needs to be built at the same time, iterating on all of it together, rather than supercharging one piece. 

I am an incredible thinker when it comes to competitive video games. I have coached overwatch professionally. I want to transition these skills into AI research. I believe that there could be ground breaking discoveries found via entities controlling avatars in video game environments. Taking a less generalist approach. A shorter simulation of a slice of time, (game time could be a life or just a day). Waking up for the day. What do you dream while not playing the game? You have limited sense in video games, vision, sound, and a sort of touch.  This might be enough for world experience grounding. When I play it feels real, I even dream of controlling a hero in games. Deadlock is the game I am thinking of right now. You need a character to control. Not something like pokemon battles or chess.

#### Skills games require
Grounded cognitive skills that current AI systems struggle with.
- Real-time decision making
- Understanding of spatial dynamics
- Cause-and-effect learning through direct experience
- Complex coordination between perception and action
- Strategic thinking that combines immediate tactics with longer-term planning

There's stuff that you could probably brute force an LLM to learn through 100000 lifetimes.
Some heavy knowledge stuff rooted in statistics about best items and sets, etc. LLMs could do this.

It's abstract ideas like pressure on the map, both spatial and temporal.

How to do movement tech, when to employ it exactly. Threat analysis. Priority creating, One particular skill in deadlock is planning 1 minute ahead of what you are doing right now. You should always be envisioning what could happen in the future. This skill requires rapid continuous optimization. Information on the map could show up that changes your current plan and you need to make an quick decision on how to react. The meta is always about adapting to current results from top players. Adaptation happens in game not just after in review. This is something LLMs cannot tackle with large data sets. It is abstract thinking.

Planning as a program
```
while(true) {
    observe();       // Current game state
    analyze();       // Potential futures
    synthesize();    // Plan formation
    if(new_info()) { 
        adapt_plan();
    }
}
```

Current AI systems optimize, through many iterations over static data. 
Lack the ability to perform rapid continuous optimization
fluid, contextual optimization
plans must be instantly revised based on new information 
We need new architectures that can perform dimensional transcendence

```
if emergent_property_detected():
    integrate(new_dimension);
    evolve(universe_model);``
```

Strong corner/weak corner knowledge demonstrates understanding of:

Space (geometry and cover)
Time (peeking advantage)
Risk/reward
Positional advantage
Line of sight mechanics


```
Gameplay Elements
├── Mechanics
│   ├── Aim
│   └── Movement Control
├── Mental
│   ├── Self Psychology
│   ├── Team Psychology
│   └── Enemy Psychology
└── Theory
    ├── Space
    │   ├── Corner Control
    │   ├── Position Control
    │   └── Map Control
    └── Time
        ├── Tempo
        ├── Proactive Play
        └── Reactive Adaptation
```

Physical execution (Mechanics)
Mental state/discipline (Mental)
Strategic principals (Theory)

#### How to tackle game learning:
Start with basic theory (space/time understanding)
Add mechanical execution
Only later tackle the complex psychological aspects

no.

It all feeds into itself. A player who is bad at aiming is going to have their other factors influenced by that. Their space understanding will be bad, they wont push because they wont be confident in hitting shots. They tend to play too passive or stupid aggro. The stupid aggro ones will probably climb faster just through sheer luck and force of will. 

It;s something like this. You have a hero with LOS on an area. That area is controlled by them based on their hero kit (theory) long range or short range, healing, etc its always game specific. but take a guy with a hammer, hammer can't miss in the area in front of them, they 100% contest that. But take a dude with a bow and arrow that hits 25% of his shots, he only contests it that much. But he can hit that one insta kill headshot so...

Also the bow and arrow guy can still be dumb happy, just going for headshots, you are far away from the action you can afford to shoot however many shots you want to.

Both are complex states.


for AI development, we might need to intentionally introduce mechanical imperfection to develop more human-like strategic understanding

The "stupid aggro" silver player might actually be learning more useful data about game states than the hesitant passive player.
This is why coaches sometimes tell players to be more aggressive and tone it back on their own terms to learn from mistakes. There is a term pro players say when they die in aggro ways "limit testing" this is literally test time learning done by humans. but in a more intentional way to break new ground.

Pro Player Limit Testing:
Intentional pushing of boundaries
Learning through calculated risks
Finding edges of possibility space
Developing feel for risk/reward
Building mechanical confidence
Discovering new strategic options

This is different from silver "stupid aggro" because it's:
Intentional vs. Random
Learning-focused vs. Result-focused
Data-gathering vs. Hoping-it-works

Does this suggest that for AI development, we might need to intentionally introduce mechanical imperfection to develop more human-like strategic understanding. This is an idea I wish to explore via the mechanical element. Where we could still introduce good amounts of theory.

No idea how to apply mental core knowledge to ai though.
Recording "confidence states" during limit testing
Tracking success/failure patterns
Building risk assessment models

the true psychological elements of gameplay (tilt, pressure, team dynamics) might need a completely different approach.

I want to create an AI that learns how to aim in Deadlock. Mechanics and theory through identifying targets, a form of decision making. Take two images, identify objects. Identify target. Calculate vector of target from image 1 to image 2. Move mouse there on a path like a human would. There is a guy who made an AI robot that could aim through a set of robotic appendages. I wish to do it software based. Move mouse on natural curve to predicted next place of target.

Components:
├── Computer Vision
│   ├── Object Detection (frame 1, frame 2)
│   ├── Target Priority System
│   └── Movement Prediction
├── Mouse Movement Generation
│   ├── Natural Curve Calculation
│   ├── Human-like Acceleration/Deceleration
│   └── Path Optimization
└── Decision Layer
    ├── Target Selection Logic
    └── Shot Timing

Key challenges/opportunities:
Creating natural mouse movement patterns (avoiding robotic straight lines)
Developing "human-like" target acquisition time
Building in deliberate mechanical imperfection
Implementing prediction for moving targets

I want to create a purely theory AI that looks at the deadlock minimap.
Components:
├── Map State Analysis
│   ├── Position Recognition
│   ├── Zone Control Calculation
│   └── Resource Distribution
├── Strategic Assessment
│   ├── Threat Analysis
│   ├── Opportunity Recognition
│   └── Territory Control
└── Temporal Planning
    ├── Short-term Predictions
    └── Long-term Strategic options

The connection is made within the minimap player indicator icon.
It's part of the same image used for aim.
It shows you where your hero is looking at.
Team vs not team. 
Could also make one that doesn't have fog of war cause replay viewer or match spectator. 
More for pro game analysis. Would probably want to start with more of a human application.

I think the first project would be just the aim vector stuff. No minimap in that yet, separate component. How to get funding for any of this? I need job, I can program. I made an auto streamer that auto spectates the game using simple computer vision opencv, ancient tech in AI terms.

Vision System Components:
├── Main Screen Analysis
│   ├── Target Detection
│   ├── Threat Assessment
│   └── Movement Prediction
└── Minimap Integration
    ├── Player Position/Facing (indicator)
    ├── Team Position Analysis
    └── Basic Zone control

World Experience Layer
├── Physical Simulation (Game Environment)
├── Multi-Modal Integration
│   ├── Visual Processing
│   ├── Spatial Awareness
│   ├── Temporal Understanding
│   └── Action-Reaction Loops
└── Rapid Optimization System
    ├── Real-time Decision Making
    ├── Continuous Adaptation
    └── Experience Integration

Learning Framework
├── Mechanical Skills
│   ├── Direct Interaction
│   └── Physical Execution
├── Theoretical Understanding
│   ├── Spatial Relations
│   ├── Temporal Dynamics
│   └── Strategic Principles
└── Psychological Elements
    ├── Risk Assessment
    ├── Confidence Modeling
    └── Adaptive Behavior

